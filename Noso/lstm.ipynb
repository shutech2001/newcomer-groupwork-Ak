{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVZxOzc8CbcD"
      },
      "source": [
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import time\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFQGGqzNDdSn"
      },
      "source": [
        "def generate_input(df, window_radius=1):\n",
        "    _data = []\n",
        "    for _, item in df.iterrows():\n",
        "        seq = item.sequence\n",
        "        length = len(seq)\n",
        "        \n",
        "        seq = (\"_\" * window_radius) + seq + (\"_\" * window_radius) #add spacer\n",
        "        for resn in range(length):\n",
        "            _in = list(seq[resn:resn+window_radius*2+1])\n",
        "            _data.append(_in)\n",
        "    return _data\n",
        "\n",
        "def generate_label(df):\n",
        "    label = []\n",
        "    for _, item in df.iterrows():\n",
        "        ss = item.label\n",
        "        for resn, _label in enumerate(ss):\n",
        "            label.append(int(_label))\n",
        "    return np.array(label)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HwBNge7DhJR"
      },
      "source": [
        "    # read csv files\n",
        "    train_val_df = pd.read_csv('/content/train.csv')\n",
        "    test_df      = pd.read_csv('/content/test.csv') \n",
        "\n",
        "    # split into train dataset and validation dataset (not train-test splitting)\n",
        "    train_df, val_df = train_test_split(train_val_df, random_state=0)\n",
        "\n",
        "    # extract subsequence\n",
        "    window_radius = 20\n",
        "    train_data_ = generate_input(train_df, window_radius)\n",
        "    val_data_   = generate_input(val_df, window_radius)\n",
        "    test_data_  = generate_input(test_df, window_radius) if (test_df is not None) else None\n",
        "\n",
        "  "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkLijnoDEvhH"
      },
      "source": [
        "# encode an amino acids sequence into a numerical vector\n",
        "# MUST use the same transformer for all data without refit\n",
        "word2index = {}\n",
        "for amino in train_data_:\n",
        "  for acid in amino:\n",
        "    if acid in word2index: continue\n",
        "    word2index[acid] = len(word2index)\n",
        "\n",
        "def sentence2index(data):\n",
        "  return [[word2index[w]  for w in s]for s in data]\n",
        "\n",
        "# データをバッチでまとめるための関数\n",
        "def train2batch(title, category, batch_size=10000):\n",
        "  title_batch = []\n",
        "  category_batch = []\n",
        "  title_shuffle, category_shuffle = shuffle(title, category)\n",
        "  for i in range(0, len(title), batch_size):\n",
        "    title_batch.append(title_shuffle[i:i+batch_size])\n",
        "    category_batch.append(category_shuffle[i:i+batch_size])\n",
        "  return title_batch, category_batch\n",
        "\n",
        "# extract label information\n",
        "# Note: NO LABEL INFORMATION for test dataset\n",
        "train_label = generate_label(train_df)\n",
        "val_label   = generate_label(val_df)\n",
        "# test_label = Non\n",
        "# rename for interpretability\n",
        "X_train, y_train = sentence2index(train_data_), train_label\n",
        "X_val,   y_val   = sentence2index(val_data_),   val_label\n",
        "X_test           = sentence2index(test_data_)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX5eaZ9lH2cb",
        "outputId": "65e64cf3-de8c-463d-c8e2-6ab4ec69bb4a"
      },
      "source": [
        "print(torch.cuda.device_count())\n",
        "# GPUを使うために必要\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCLvGiYTIFBY"
      },
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "    # モデルで使う各ネットワークをコンストラクタで定義\n",
        "      def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        # 親クラスのコンストラクタ。決まり文句\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # インプットの単語をベクトル化するために使う\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # LSTMの隠れ層。これ１つでOK。超便利。 batch_first=Trueが大事！\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "        # softmaxのLog版。dim=0で列、dim=1で行方向を確率変換。\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    # 順伝播処理はforward関数に記載\n",
        "      def forward(self, sentence):\n",
        "        # 文章内の各単語をベクトル化して出力。2次元のテンソル\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        # 2次元テンソルをLSTMに食わせられる様にviewで３次元テンソルにした上でLSTMへ流す。\n",
        "        # 上記で説明した様にmany to oneのタスクを解きたいので、第二戻り値だけ使う。\n",
        "        _, lstm_out = self.lstm(embeds)\n",
        "        # lstm_out[0]は３次元テンソルになってしまっているので2次元に調整して全結合。\n",
        "        tag_space = self.hidden2tag(lstm_out[0])\n",
        "        # softmaxに食わせて、確率として表現\n",
        "        tag_scores = self.softmax(tag_space.squeeze())\n",
        "        return tag_scores\n",
        "    "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UavlSdF4IMXi",
        "outputId": "7f1f1b8e-81ed-4096-ec47-4c39c84543ba"
      },
      "source": [
        "# 単語のベクトル次元数\n",
        "EMBEDDING_DIM = 10\n",
        "# 隠れ層の次元数\n",
        "HIDDEN_DIM = 128\n",
        "# データ全体の単語数\n",
        "VOCAB_SIZE = len(word2index)\n",
        "# 分類先のカテゴリの数\n",
        "TAG_SIZE = 2\n",
        "# モデル宣言\n",
        "model = LSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TAG_SIZE).to(device)\n",
        "# 損失関数はNLLLoss()を使う。LogSoftmaxを使う時はこれを使うらしい。\n",
        "loss_function = nn.NLLLoss()\n",
        "# 最適化の手法はadam\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# 各エポックの合計loss値を格納する\n",
        "losses = []\n",
        "\n",
        "# 100ループ回してみる。\n",
        "for epoch in range(27):\n",
        "    \n",
        "    all_loss = 0\n",
        "    title_batch, category_batch = train2batch(X_train, y_train)\n",
        "    for i in range(len(title_batch)):\n",
        "        batch_loss = 0\n",
        "        model.zero_grad()\n",
        "        # 順伝搬させるtensorはGPUで処理させるためdevice=にGPUをセット\n",
        "        title_tensor = torch.tensor(title_batch[i], device=device)\n",
        "        # category_tensor.size() = (batch_size × 1)なので、squeeze()\n",
        "        category_tensor = torch.tensor(category_batch[i], device=device).squeeze()\n",
        "        \n",
        "        out = model(title_tensor)\n",
        "        batch_loss = loss_function(out, category_tensor)\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        all_loss += batch_loss.item()\n",
        "    print(\"epoch\", epoch, \"\\t\" , \"loss\", all_loss)\n",
        "\n",
        "    if epoch > 20:\n",
        "      test_num = len(X_val)\n",
        "      # 正解の件数\n",
        "      a = 0\n",
        "      #  勾配自動計算OFF\n",
        "      with torch.no_grad():\n",
        "          title_batch, category_batch = train2batch(X_val, y_val)\n",
        "          allprob = []\n",
        "          for i in range(len(title_batch)):\n",
        "            title_tensor = torch.tensor(title_batch[i], device=device)\n",
        "            category_tensor = torch.tensor(category_batch[i], device=device)\n",
        "            out = model(title_tensor)\n",
        "            _, predicts = torch.max(out, 1)\n",
        "            prob = torch.exp(out[:,1])\n",
        "            allprob.append(prob)\n",
        "            for j, ans in enumerate(category_tensor):\n",
        "                if predicts[j].item() == ans.item():\n",
        "                    a += 1\n",
        "      print( a / test_num)\n",
        "      prob_1 = torch.cat(allprob, 0)\n",
        "      y_val_batch = np.concatenate(category_batch, axis=0)\n",
        "      auc = roc_auc_score(y_val_batch , prob_1.to('cpu').detach().numpy().copy()) \n",
        "      print(auc)\n",
        "      \n",
        "    if all_loss < 0.1: break\n",
        "print(\"done.\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 \t loss 59.9971039891243\n",
            "epoch 1 \t loss 56.482780396938324\n",
            "epoch 2 \t loss 55.3305498957634\n",
            "epoch 3 \t loss 52.67639145255089\n",
            "epoch 4 \t loss 48.47841390967369\n",
            "epoch 5 \t loss 47.09657695889473\n",
            "epoch 6 \t loss 46.39263787865639\n",
            "epoch 7 \t loss 45.89206862449646\n",
            "epoch 8 \t loss 45.33062794804573\n",
            "epoch 9 \t loss 44.26288402080536\n",
            "epoch 10 \t loss 43.55077689886093\n",
            "epoch 11 \t loss 42.96271473169327\n",
            "epoch 12 \t loss 42.51873764395714\n",
            "epoch 13 \t loss 42.134491711854935\n",
            "epoch 14 \t loss 41.76576465368271\n",
            "epoch 15 \t loss 41.58200490474701\n",
            "epoch 16 \t loss 41.36629980802536\n",
            "epoch 17 \t loss 41.18223479390144\n",
            "epoch 18 \t loss 40.99389007687569\n",
            "epoch 19 \t loss 40.99745041131973\n",
            "epoch 20 \t loss 40.76394349336624\n",
            "0.8331262091484136\n",
            "0.8569548164306435\n",
            "epoch 21 \t loss 40.59872505068779\n",
            "0.835273736564648\n",
            "0.8571294966193426\n",
            "epoch 22 \t loss 40.52067109942436\n",
            "0.8352338196981752\n",
            "0.8578447450121459\n",
            "epoch 23 \t loss 40.45892861485481\n",
            "0.8359549844191164\n",
            "0.8579443161445832\n",
            "epoch 24 \t loss 40.28854137659073\n",
            "0.8333630492228186\n",
            "0.8567163070894371\n",
            "epoch 25 \t loss 40.17070925235748\n",
            "0.8360800572673978\n",
            "0.8584100777287151\n",
            "epoch 26 \t loss 40.06878060102463\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sahU53ana42q"
      },
      "source": [
        "###### 4. prediction for test dataset ######\n",
        "\n",
        "if (test_df is not None) and (X_test is not None):\n",
        "    with torch.no_grad():\n",
        "          title_batch = []\n",
        "          for i in range(0, len(X_test), 10000):\n",
        "            title_batch.append(X_test[i:i+10000])\n",
        "          allprob = []\n",
        "          for i in range(len(title_batch)):\n",
        "            title_tensor = torch.tensor(title_batch[i], device=device)\n",
        "            out = model(title_tensor)\n",
        "            _, predicts = torch.max(out, 1)\n",
        "            prob = torch.exp(out[:,1])\n",
        "            allprob.append(prob)\n",
        "    prob_1 = torch.cat(allprob, 0)\n",
        "      \n",
        "    predicted = prob_1.to('cpu').detach().numpy().copy()\n",
        "    sequence_id_list    = []\n",
        "    residue_number_list = []\n",
        "    for _, item in test_df.iterrows():\n",
        "        sequence_id = item.sequence_id\n",
        "        sequence    = item.sequence\n",
        "        for i, aa in enumerate(sequence):\n",
        "            sequence_id_list.append(sequence_id)\n",
        "            residue_number_list.append(i+1) #0-origin to 1-origin\n",
        "    predicted_df = pd.DataFrame.from_dict({\n",
        "        \"sequence_id\": sequence_id_list,\n",
        "        \"residue_number\": residue_number_list,\n",
        "        \"predicted_value\": predicted,\n",
        "        })\n",
        "\n",
        "    predicted_df.to_csv('output.csv', index=None)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ZPBG-74Qt4KL",
        "outputId": "90a4476c-2d9e-457f-ca84-8189f858e585"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('output.csv')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_78ba33f1-3780-404a-92b1-2e0e9788be2b\", \"output.csv\", 13106117)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwbAtJRGJgj7",
        "outputId": "8701204a-c9d3-4907-d1c5-8e3593d0fd08"
      },
      "source": [
        "test_num = len(X_val)\n",
        "# 正解の件数\n",
        "a = 0\n",
        "#  勾配自動計算OFF\n",
        "with torch.no_grad():\n",
        "    title_batch, category_batch = train2batch(X_val, y_val)\n",
        "    allprob = []\n",
        "    for i in range(len(title_batch)):\n",
        "      title_tensor = torch.tensor(title_batch[i], device=device)\n",
        "      category_tensor = torch.tensor(category_batch[i], device=device)\n",
        "      out = model(title_tensor)\n",
        "      _, predicts = torch.max(out, 1)\n",
        "      prob = torch.exp(out[:,1])\n",
        "      allprob.append(prob)\n",
        "      for j, ans in enumerate(category_tensor):\n",
        "          if predicts[j].item() == ans.item():\n",
        "              a += 1\n",
        "print( a / test_num)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8365058371764406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMvPMt8NTCg_",
        "outputId": "cb010804-3453-4fa0-952d-339f85bd11c4"
      },
      "source": [
        "prob_1 = torch.cat(allprob, 0)\n",
        "y_val_batch = np.concatenate(category_batch, axis=0)\n",
        "auc = roc_auc_score(y_val_batch , prob_1.to('cpu').detach().numpy().copy()) \n",
        "print(auc)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8590307932335519\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}