{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375781, 901)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "def generate_input(df, window_radius = 3):\n",
    "    _data = []\n",
    "    for _, item in df.iterrows():\n",
    "        seq = item.sequence\n",
    "        length = len(seq)\n",
    "        \n",
    "        seq = (\"_\" * window_radius) + seq + (\"_\" * window_radius) #add spacer\n",
    "        for resn in range(length):\n",
    "            _in = list(seq[resn:resn+window_radius*2+1])\n",
    "            _data.append(_in)\n",
    "    return _data\n",
    "\n",
    "def generate_label(df):\n",
    "    label = []\n",
    "    for _, item in df.iterrows():\n",
    "        ss = item.label\n",
    "        for resn, _label in enumerate(ss):\n",
    "            label.append(int(_label))\n",
    "    return np.array(label)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "\n",
    "    ###### 1. data preparation ######\n",
    "    \n",
    "    # read csv files\n",
    "    train_val_df = pd.read_csv('train.csv')\n",
    "    test_df      = pd.read_csv('test.csv') \n",
    "\n",
    "    # split into train dataset and validation dataset (not train-test splitting)\n",
    "    train_df, val_df = train_test_split(train_val_df, random_state=0)\n",
    "\n",
    "    # extract subsequence\n",
    "    window_radius = 20\n",
    "    train_data_ = generate_input(train_df, window_radius)\n",
    "    val_data_   = generate_input(val_df, window_radius)\n",
    "    test_data_  = generate_input(test_df, window_radius) \n",
    "    \n",
    "    # encode an amino acids sequence into a numerical vector\n",
    "    # MUST use the same transformer for all data without refit \n",
    "    transformer = OneHotEncoder().fit(train_data_)\n",
    "    train_data  = transformer.transform(train_data_)\n",
    "    val_data    = transformer.transform(val_data_)\n",
    "    test_data   = transformer.transform(test_data_)\n",
    "\n",
    "    # extract label information\n",
    "    # Note: NO LABEL INFORMATION for test dataset\n",
    "    train_label = generate_label(train_df)\n",
    "    val_label   = generate_label(val_df)\n",
    "    # test_label = None\n",
    "\n",
    "\n",
    "    # rename for interpretability\n",
    "    X_train, Y_train = train_data, train_label\n",
    "    X_val,   Y_val   = val_data,   val_label\n",
    "    X_test           = test_data\n",
    "    \n",
    "    print(np.shape(X_val))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "559/559 [==============================] - 15s 23ms/step - loss: 0.4623 - accuracy: 0.7912 - val_loss: 0.4077 - val_accuracy: 0.8180\n",
      "Epoch 2/10\n",
      "559/559 [==============================] - 14s 21ms/step - loss: 0.3909 - accuracy: 0.8269 - val_loss: 0.3915 - val_accuracy: 0.8261\n",
      "Epoch 3/10\n",
      "559/559 [==============================] - 13s 20ms/step - loss: 0.3624 - accuracy: 0.8407 - val_loss: 0.3925 - val_accuracy: 0.8263\n",
      "Epoch 4/10\n",
      "559/559 [==============================] - 12s 20ms/step - loss: 0.3440 - accuracy: 0.8499 - val_loss: 0.3973 - val_accuracy: 0.8246\n",
      "Epoch 5/10\n",
      "559/559 [==============================] - 13s 20ms/step - loss: 0.3274 - accuracy: 0.8589 - val_loss: 0.4054 - val_accuracy: 0.8220\n",
      "Epoch 6/10\n",
      "559/559 [==============================] - 13s 20ms/step - loss: 0.3126 - accuracy: 0.8658 - val_loss: 0.4160 - val_accuracy: 0.8200\n",
      "Epoch 7/10\n",
      "559/559 [==============================] - 13s 20ms/step - loss: 0.3007 - accuracy: 0.8716 - val_loss: 0.4262 - val_accuracy: 0.8165\n",
      "Epoch 8/10\n",
      "559/559 [==============================] - 13s 20ms/step - loss: 0.2895 - accuracy: 0.8774 - val_loss: 0.4382 - val_accuracy: 0.8152\n",
      "Epoch 9/10\n",
      "559/559 [==============================] - 13s 20ms/step - loss: 0.2790 - accuracy: 0.8824 - val_loss: 0.4516 - val_accuracy: 0.8111\n",
      "Epoch 10/10\n",
      "559/559 [==============================] - 13s 20ms/step - loss: 0.2700 - accuracy: 0.8868 - val_loss: 0.4684 - val_accuracy: 0.8107\n"
     ]
    }
   ],
   "source": [
    "    model = Sequential()\n",
    "    model.add(Dense(200, input_dim = 901, activation = 'relu')) \n",
    "    model.add(Dense(300, activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, Y_train, epochs=10, batch_size=2000, validation_data=(X_val, Y_val))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.3320662e-08 3.7277490e-02 9.2642099e-02 ... 2.6901633e-02 1.3138056e-03\n",
      " 1.5978113e-09]\n"
     ]
    }
   ],
   "source": [
    "    predicted = model.predict(X_test)\n",
    "    predicted = np.array(predicted).flatten()\n",
    "    print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    sequence_id_list    = []\n",
    "    residue_number_list = []\n",
    "    for _, item in test_df.iterrows():\n",
    "        sequence_id = item.sequence_id\n",
    "        sequence    = item.sequence\n",
    "        for i, aa in enumerate(sequence):\n",
    "            sequence_id_list.append(sequence_id)\n",
    "            residue_number_list.append(i+1) #0-origin to 1-origin\n",
    "\n",
    "    predicted_df = pd.DataFrame.from_dict({\n",
    "        \"sequence_id\": sequence_id_list,\n",
    "        \"residue_number\": residue_number_list,\n",
    "        \"predicted_value\": predicted,\n",
    "        })\n",
    "    predicted_df.to_csv('output_5_layer_nn_1.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
